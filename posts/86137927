<p><em>But it also has some unfinished business regulating online platforms, argues Mark MacCarthy, author of the forthcoming book, <a href="https://www.amazon.com/Regulating-Digital-Industries-Oversight-Competition-ebook/dp/B0C4GDTNDZ/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Regulating Digital Industries</a></em>, </p>



<figure><img src="https://reader.miniflux.app/proxy/z4jrCntbIdmjaHkbXadNY_iP2iL1Vh0x2iLMSFzk_AI=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0FJLUZvcnVtLVNjaHVtZXItMTAyNHg1NzYucG5n" alt="Sen. Martin Heinrich (D-NM), Sen. Mike Rounds (R-SD), Senate Majority Leader Charles Schumer (D-NY), and Sen. Todd Young (R-IN), also known as the “Gang of Four,” hosted the first AI Insight Forum on September 13, 2023." srcset="https://reader.miniflux.app/proxy/z4jrCntbIdmjaHkbXadNY_iP2iL1Vh0x2iLMSFzk_AI=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0FJLUZvcnVtLVNjaHVtZXItMTAyNHg1NzYucG5n 1024w, https://reader.miniflux.app/proxy/4ybfZgwQQ48Kavl-D2WnyRleQCmEagL6clbDF7JLsuA=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0FJLUZvcnVtLVNjaHVtZXItMzAweDE2OS5wbmc= 300w, https://reader.miniflux.app/proxy/byh9dYhPNQ00qtMRWlROAMf17WSRRGS__zE0aataTVg=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0FJLUZvcnVtLVNjaHVtZXItNzY4eDQzMi5wbmc= 768w, https://reader.miniflux.app/proxy/QABiWhG471IDhj_0GH8_C1JIUluTB6WAT3X7xU8UMPw=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0FJLUZvcnVtLVNjaHVtZXIucG5n 1200w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy"/><figcaption><em>Sen. Martin Heinrich (D-NM), Sen. Mike Rounds (R-SD), Senate Majority Leader Charles Schumer (D-NY), and Sen. Todd Young (R-IN), also known as the “Gang of Four,” hosted the first AI Insight Forum on September 13, 2023. </em><a href="https://senrounds.app.box.com/s/bnh95m17sx14o0458kfuuavi22jxhxld/file/1307211218072" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"><em>Source</em></a></figcaption></figure>


<p>Since the explosion of ChatGPT about a year ago, it seems that policymakers everywhere want to regulate artificial intelligence. It has become a focus of Congressional attention with Senator Chuck Schumer’s recent <a href="https://www.democrats.senate.gov/newsroom/press-releases/majority-leader-schumer-opening-remarks-for-the-senates-inaugural-ai-insight-forum" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">AI Insight Forum</a>.  This is all to the good, given that many of our troubles with the online world stem from a failure to regulate early on, when real and potential harms of a new technology are already apparent. </p>



<p>But there is a right way to do it and a wrong way. Moreover, in pursuing the shiny new toy of AI regulation, Congress should not neglect the vital task of regulating digital platforms. </p>



<p>For three administrations, the US has followed the principle of regulating the uses of AI, not the technology itself.  This comes from taking seriously the conclusion reached years ago by the Stanford University Study Panel of AI experts <a href="https://ai100.stanford.edu/sites/g/files/sbiybj18871/files/media/file/ai100report10032016fnl_singles.pdf" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">that</a> “…attempts to regulate ‘AI’ in general would be misguided, since there is no clear definition of AI (it isn’t any one thing), and the risks and considerations are very different in different domains.” </p>



<p>In this sector-specific approach, if AI is used, for instance, to assess creditworthiness, the Consumer Financial Protection Bureau must make sure the assessment follows the fair lending laws. If AI is used to make employment or promotion decisions, the Equal Employment Opportunity Commission should make sure it doesn’t discriminate against legally protected classes.</p>



<p>Federal Trade Commission Chair Lina Khan <a href="https://www.washingtonpost.com/technology/2023/04/25/artificial-intelligence-bias-eeoc/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">summarized</a> this approach to AI regulation as “There is no AI exception to the laws on the books.”  </p>



<p>But more might need to be done than to apply current law. In moving beyond this current approach, Congress might consider what the United Kingdom is doing. In its recent <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper#part-3-an-innovative-and-iterative-approach" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">white paper</a>, the UK government also focuses on AI as used in context. But, in addition, the UK government urges its regulators to consider some cross-cutting AI principles including safety, transparency, fairness, accountability, and redress. After a time, the government suggests, it might require regulators to give “due regard” to these principles. But it has ruled out creating a new AI agency to regulate AI as such or attempting the impossible task of regulating AI in all its uses. </p>



<p>My colleague at Brookings, Alex Engler, makes this incremental approach more specific.  Instead of requiring regulators to give due regard to vague AI principles, he <a href="https://www.brookings.edu/articles/a-comprehensive-and-distributed-approach-to-ai-regulation/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">suggests</a> expanding the powers of existing agencies to enable them to meet the special challenges of AI. This would include enabling them to provide the public with disclosures of AI use, meaningful information about computational processes, access and correction of data, and a right to opt out of algorithmic decision making. New authority might also empower existing regulators to require AI systems to be accurate both overall and for protected demographic groups. Regulators might also be authorized to gain access to training data and the AI model itself.</p>



<p>Congress should move this idea to the top of its agenda. It meets some of the special challenges of AI without establishing a new AI regulator.</p>



<p>But it is not enough to give existing regulators new powers to regulate AI within the areas of their jurisdiction. This is because AI applications can greatly exacerbate <em>unregulated</em> harms such as privacy invasions as well as manipulation and misinformation, especially in the context of political campaigns. Existing laws simply don’t address those challenges. </p>



<p>The answer to those problems, however, is not to regulate the AI models. It is to pass laws addressing these unregulated harms, and in the process to make sure that regulators have the power to prevent them from being exacerbated through the use of AI tools. </p>



<p>There’s some low-hanging legislative fruit for Congress to grab. The <a href="https://docs.house.gov/meetings/IF/IF00/20220720/115041/BILLS-1178152rh.pdf" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">American Data Protection and Privacy Act</a> (ADPPA) would establish a national privacy law; it almost made it through Congress last year. The <a href="https://www.warner.senate.gov/public/index.cfm/the-honest-ads-act" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Honest Ads Act</a> would require digital sponsorship identification for political ads, and is another law that has been pending for several years. <a href="https://www.coons.senate.gov/imo/media/doc/pata_one_pager_118th_congress_june_2023.pdf" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Platform accountability legislation</a> would mandate transparency, explanations for user takedowns, risk assessments, and access to data for researchers; this common sense proposal also languished in the last Congress.  All of these measures would address AI issues in these policy areas. It is timely and urgent to take these measures up in the current Congress.  </p>



<figure><img width="200" height="300" src="https://reader.miniflux.app/proxy/NK3VBAQeW_vxFZH5_KHEwesaCMucl1o9i_3g1EeVsas=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0NvdmVyLUltYWdlLTIwMHgzMDAuanBlZw==" alt="" srcset="https://reader.miniflux.app/proxy/NK3VBAQeW_vxFZH5_KHEwesaCMucl1o9i_3g1EeVsas=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0NvdmVyLUltYWdlLTIwMHgzMDAuanBlZw== 200w, https://reader.miniflux.app/proxy/odvGmjQ4E58dJee8RU5PjEPK7EF35y3xb5Zve1k3KFA=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0NvdmVyLUltYWdlLTY4MngxMDI0LmpwZWc= 682w, https://reader.miniflux.app/proxy/7vSjZgERUX0wf-H69-3nwRBHwL9ahWSRyFUUHajyAzo=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0NvdmVyLUltYWdlLTc2OHgxMTUyLmpwZWc= 768w, https://reader.miniflux.app/proxy/oMXGNmZQAKnNPrY48hkIPct-fxih7sxC5X7v2L2oJp0=/aHR0cHM6Ly90ZWNocG9saWN5LnByZXNzL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDIzLzEwL0NvdmVyLUltYWdlLmpwZWc= 853w" sizes="(max-width: 200px) 100vw, 200px" loading="lazy"/></figure>


<p>But there’s also a push for a new digital regulator to address online harms. In my forthcoming book, <a href="https://www.amazon.com/Regulating-Digital-Industries-Oversight-Competition-ebook/dp/B0C4GDTNDZ/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"><em>Regulating Digital Industries</em></a>, I outline how a digital regulator must be empowered to promote competition, privacy, and good content moderation in the lines of business that are so central to the digital economy of the 21<sup>st</sup> century. This would include search, social media, ecommerce, mobile app infrastructure and ad tech. A digital regulator would have full authority over AI used to violate these new requirements. </p>



<p>A dedicated digital regulator is an idea whose time is coming. Recently Senators Elizabeth Warren (D-MA) and Lindsey Graham (R-SC) introduced the <a href="https://www.congress.gov/bill/118th-congress/senate-bill/2597/text?s=1&amp;r=4&amp;q=%7B%22search%22%3A%22open+app+market%22%7D" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Digital Consumer Protection Commission Act</a> to regulate digital companies with respect to competition, privacy, transparency and national security. They join Senators Michael Bennet (D-CO) and Peter Welch (D-VT) whose <a href="https://www.congress.gov/bill/118th-congress/senate-bill/1671/text?s=6&amp;r=1&amp;q=%7B%22search%22%3A%22Peter+digital%22%7D" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Digital Platform Commission Act</a> would also establish a digital regulator. Both proposals provide the regulator with authority over AI systems used by digital platforms. </p>



<p>Should Congress regulate AI? Of course, and the way forward should be to grant agencies new powers to meet AI challenges.  </p>



<p>But Congress can do more than one thing at a time. It has some unfinished business in regulating the industries that are at the core of our digital economy. It should take up the task of establishing a modern, agile regulatory structure for digital industries.</p>
<p>The post <a href="https://techpolicy.press/congress-should-regulate-artificial-intelligence/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Congress Should Regulate Artificial Intelligence</a> appeared first on <a href="https://techpolicy.press" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Tech Policy Press</a>.</p>
