<p>Welcome to the AI Safety Newsletter by the <a href="https://www.safe.ai/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Center for AI Safety</a>. We discuss developments in AI and AI safety. No technical background required.</p><p><a href="https://newsletter.safe.ai/subscribe?" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Subscribe now</a></p><h2>White House Unveils Voluntary Commitments to AI Safety from Leading AI Labs</h2><p>Last Friday, the White House <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">announced</a> a series of voluntary <a href="https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">commitments</a> from seven of the world&#39;s premier AI labs. Amazon, Anthropic, Google, Inflection, Meta, Microsoft, and OpenAI pledged to uphold these commitments, which are non-binding and pertain only to forthcoming &#34;frontier models&#34; superior to currently available AI systems. The White House also notes that the Biden-Harris Administration is developing an executive order alongside these voluntary commitments.</p><p>The commitments are timely and technically well-informed, demonstrating the ability of federal policymakers to respond capably and quickly to AI risks. The Center for AI Safety <a href="https://www.safe.ai/post/leading-ai-companies-join-white-houses-voluntary-commitment-to-enhance-ai-safety" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">supports</a> these commitments as a precedent for cooperation on AI safety and legally binding legislation. </p><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddb29af-7413-4279-97dd-7de347e7b61a_1600x831.png" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"><picture><source type="image/webp" srcset="https://reader.miniflux.app/proxy/zFR_5Gzy4iblvXqtJRA5-wr4L0cesionTFAP4X1nQDo=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYyZGRiMjlhZi03NDEzLTQyNzktOTdkZC03ZGUzNDdlN2I2MWFfMTYwMHg4MzEucG5n 424w, https://reader.miniflux.app/proxy/NfkMb0Nvp0a5Jeopz2Jkql-nBqngJE_mzizv1PDO_SI=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYyZGRiMjlhZi03NDEzLTQyNzktOTdkZC03ZGUzNDdlN2I2MWFfMTYwMHg4MzEucG5n 848w, https://reader.miniflux.app/proxy/UWJ3FI3NhjyxSu4Nw3piJWGHah1DhCjHxj_6WmrQrGU=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMmRkYjI5YWYtNzQxMy00Mjc5LTk3ZGQtN2RlMzQ3ZTdiNjFhXzE2MDB4ODMxLnBuZw== 1272w, https://reader.miniflux.app/proxy/vCkE1DxLAA8YtiphUadPWoZqpbEWrQ3quCZSKi5frxI=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMmRkYjI5YWYtNzQxMy00Mjc5LTk3ZGQtN2RlMzQ3ZTdiNjFhXzE2MDB4ODMxLnBuZw== 1456w" sizes="100vw"/><img src="https://reader.miniflux.app/proxy/zze5vusU8xY_xGfFu0equDnXGZnPSbXK51M6y2Qw7Us=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMmRkYjI5YWYtNzQxMy00Mjc5LTk3ZGQtN2RlMzQ3ZTdiNjFhXzE2MDB4ODMxLnBuZw==" alt="" srcset="https://reader.miniflux.app/proxy/vbTrLi4MBxzX0L3OfIffWmHpo4EueEJCrHH_ZCX2qzc=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYyZGRiMjlhZi03NDEzLTQyNzktOTdkZC03ZGUzNDdlN2I2MWFfMTYwMHg4MzEucG5n 424w, https://reader.miniflux.app/proxy/OOxkQoY6lcdDmBJCoYhNij3mC7sUH0mBXrzAdeeP2XM=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYyZGRiMjlhZi03NDEzLTQyNzktOTdkZC03ZGUzNDdlN2I2MWFfMTYwMHg4MzEucG5n 848w, https://reader.miniflux.app/proxy/xRaBHPHTrNN2TXJucLNwT4Ij0pWEQK_LtmyY7Mkphvc=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMmRkYjI5YWYtNzQxMy00Mjc5LTk3ZGQtN2RlMzQ3ZTdiNjFhXzE2MDB4ODMxLnBuZw== 1272w, https://reader.miniflux.app/proxy/zze5vusU8xY_xGfFu0equDnXGZnPSbXK51M6y2Qw7Us=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMmRkYjI5YWYtNzQxMy00Mjc5LTk3ZGQtN2RlMzQ3ZTdiNjFhXzE2MDB4ODMxLnBuZw== 1456w" sizes="100vw" loading="lazy"/></picture></a></figure><p><strong>Commitments to Red Teaming and Information Sharing. </strong>AI systems <a href="https://www.jasonwei.net/blog/emergence" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">often develop unexpected capabilities</a> during training, so it’s important to <a href="https://newsletter.safe.ai/p/ai-safety-newsletter-8" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">screen models for potentially harmful abilities</a>. The companies promised to “red team” their models by searching for ways the models could cause harm, particularly in <a href="https://arxiv.org/abs/2306.12001" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">areas of potential catastrophe</a> including biological weapons acquisition, offensive cyberattacks, and self-replication. External red teamers will also be offered a chance to find vulnerabilities in these frontier AI systems.</p><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6ce818-85dc-4c0e-aa71-ba770fc799c1_2750x698.png" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"><picture><source type="image/webp" srcset="https://reader.miniflux.app/proxy/4B5ladjL6tJsUjG3fgimPN52db3j3rpYynI3LpHbr7A=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiYjZjZTgxOC04NWRjLTRjMGUtYWE3MS1iYTc3MGZjNzk5YzFfMjc1MHg2OTgucG5n 424w, https://reader.miniflux.app/proxy/g2yhD6m0L6zflHabb3JV47o8IjivS3PhUTIu0uiwlD8=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiYjZjZTgxOC04NWRjLTRjMGUtYWE3MS1iYTc3MGZjNzk5YzFfMjc1MHg2OTgucG5n 848w, https://reader.miniflux.app/proxy/mOdYgVzKRKR6-wcyQPTdK6RjQGyCBjzN7hzjCDGdua4=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYmI2Y2U4MTgtODVkYy00YzBlLWFhNzEtYmE3NzBmYzc5OWMxXzI3NTB4Njk4LnBuZw== 1272w, https://reader.miniflux.app/proxy/F6vBoaiVS-pqCi5c2OFCVVWkRENnERTRahANqVXocSI=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYmI2Y2U4MTgtODVkYy00YzBlLWFhNzEtYmE3NzBmYzc5OWMxXzI3NTB4Njk4LnBuZw== 1456w" sizes="100vw"/><img src="https://reader.miniflux.app/proxy/TJdpTUiNMs1XMvYLPbj5RwDvNvI90QSJgJkb0lkcn60=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYmI2Y2U4MTgtODVkYy00YzBlLWFhNzEtYmE3NzBmYzc5OWMxXzI3NTB4Njk4LnBuZw==" alt="" srcset="https://reader.miniflux.app/proxy/AYD89ntB8a-Ax9pYTXkTB1nyJU7rAGZO-Fc1Vyq5zUg=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiYjZjZTgxOC04NWRjLTRjMGUtYWE3MS1iYTc3MGZjNzk5YzFfMjc1MHg2OTgucG5n 424w, https://reader.miniflux.app/proxy/TqVlye0IHKfUn1OQUWXO_UCP6zedPS3H950r9I2jd2M=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiYjZjZTgxOC04NWRjLTRjMGUtYWE3MS1iYTc3MGZjNzk5YzFfMjc1MHg2OTgucG5n 848w, https://reader.miniflux.app/proxy/AbdDNoVKiuK3nEweYVzwgsrBh-geFtD-5aJsfus2jhM=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYmI2Y2U4MTgtODVkYy00YzBlLWFhNzEtYmE3NzBmYzc5OWMxXzI3NTB4Njk4LnBuZw== 1272w, https://reader.miniflux.app/proxy/TJdpTUiNMs1XMvYLPbj5RwDvNvI90QSJgJkb0lkcn60=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYmI2Y2U4MTgtODVkYy00YzBlLWFhNzEtYmE3NzBmYzc5OWMxXzI3NTB4Njk4LnBuZw== 1456w" sizes="100vw" loading="lazy"/></picture></a><figcaption><em>These are the  catastrophic capabilities that companies agreed to evaluate via red teaming.</em></figcaption></figure><p>The companies have additionally agreed to share information about best practices in AI safety with governments and each other. Public reports on system capabilities and risks are also part of this pledge, though companies have not agreed to the disclosure of model training data, which likely contains large volumes of copyrighted content. </p><p><strong>Cybersecurity to protect AI models, if companies choose. </strong>The AI labs also reiterated their dedication to cybersecurity. This helps prevent potent AI models from being accessed and misused by malicious actors. By reducing the likelihood that someone else will steal their cutting edge secrets, cybersecurity also alleviates the pressure of the AI race and gives companies more time to evaluate and enhance the safety features of their models. </p><p>Notably, while most labs aim to prevent their models from being used for malicious purposes, companies are not prohibited from sharing their models publicly. Meta, after accidentally leaking their first LLaMA model, has <a href="https://ai.meta.com/llama/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">published their LLaMA 2 model online</a> for nearly anyone to use. Meta published a report about LLaMA 2’s safety features, but only a week after its release, someone has published an “<a href="https://huggingface.co/spaces/mikeee/llama2-7b-chat-uncensored-ggml" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">uncensored</a>” version of the model.</p><p><strong>Identifying AI outputs in the wild. </strong>Companies also committed to watermarking AI outputs so they can be differentiated from text written by humans and real world images and videos. Without this crucial ability to distinguish AI outputs from real life, <a href="https://newsletter.safe.ai/p/ai-safety-newsletter-7" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">society would be vulnerable</a> to scams, <a href="https://www.theatlantic.com/technology/archive/2023/05/problem-counterfeit-people/674075/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">counterfeit people</a>, personalized persuasion, and propaganda campaigns. </p><p>Technical researchers had <a href="https://arxiv.org/abs/2303.11156" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">speculated that watermarking might be unsolvable</a> because AI systems are trained to mimic real world data as closely as possible. But companies already keep databases of most of their AI outputs, which a <a href="https://arxiv.org/abs/2303.13408" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">recent paper</a> suggests can be used to verify AI outputs. Consumers would be able to submit text, audio, or video to a company’s website and find out if it had been generated by the company’s AI models. </p><p><strong>Goals for future AI policy work. </strong>While the voluntary commitments offer a starting point, they cannot replace legally binding obligations to guide AI development for public benefit. OpenAI’s <a href="https://openai.com/blog/moving-ai-governance-forward" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">announcement</a> of the commitments says, “Companies intend these voluntary commitments to remain in effect until regulations covering substantially the same issues come into force.”</p><p>A more ambitious proposal comes from a <a href="https://arxiv.org/abs/2307.03718" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">new paper</a> proposing a three pronged approach to AI governance. First, safety standards must be developed by experts external to AI labs, similar to safety standards in healthcare, nuclear engineering, and aviation. Governments need visibility on the most powerful models being trained by AI labs, facilitated by <a href="https://carnegieendowment.org/2023/07/12/it-s-time-to-create-national-registry-for-large-ai-models-pub-90180" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">registration of advanced models</a> and protections for whistleblowers. Equipped with safety standards and a clear view of advanced AI systems, the government can ensure the standards are upheld, first by securing voluntary commitments from AI labs and later with binding laws and enforcement. </p><p>Other future commitments could include accepting legal liability for AI-induced damages, sharing training data of large pretrained models, and funding research on AI safety topics such as robustness, monitoring, and control. Notably, while companies promised to assess the risks posed by their AI systems, they did not commit to any particular response to those risks, nor promise not to deploy models that cross a “red line” of dangerous capabilities. </p><p><a href="https://newsletter.safe.ai/subscribe?" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Subscribe now</a></p><h2>Lessons from <em>Oppenheimer</em></h2><p>Last week, <em>Oppenheimer</em> opened in theaters. The film’s director, Christopher Nolan, said in <a href="https://www.theguardian.com/technology/2023/jul/21/christopher-nolan-says-ai-experts-face-their-oppenheimer-moment" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">an interview</a> that the film parallels the rise and risks of AI. AI, he said, is having its “Oppenheimer moment.” There are indeed many parallels between the development of nuclear weapons and AI. In this story, we explore one: the irrational dismissal of existential risk.</p><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dae7fb-99b2-4cfb-bc11-9f972e134bb4_1200x630.png" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"><picture><source type="image/webp" srcset="https://reader.miniflux.app/proxy/SA8n2c2PCcLvI5HtQ5SERGB8Lw_KHCEl2r4vrppaX5U=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYwNWRhZTdmYi05OWIyLTRjZmItYmMxMS05Zjk3MmUxMzRiYjRfMTIwMHg2MzAucG5n 424w, https://reader.miniflux.app/proxy/qIiZAVV4BZdUZRksiZYE9scUzfzjk7XA_RYFnPZO_gs=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYwNWRhZTdmYi05OWIyLTRjZmItYmMxMS05Zjk3MmUxMzRiYjRfMTIwMHg2MzAucG5n 848w, https://reader.miniflux.app/proxy/Ksd3AedVMufGS9wpB4lIlrNtWb5dPTlVpLKR8Z8k43M=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMDVkYWU3ZmItOTliMi00Y2ZiLWJjMTEtOWY5NzJlMTM0YmI0XzEyMDB4NjMwLnBuZw== 1272w, https://reader.miniflux.app/proxy/VKeuN3glP-luuDwnec6pgkiaSRc-NCalGerIm41Mye0=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMDVkYWU3ZmItOTliMi00Y2ZiLWJjMTEtOWY5NzJlMTM0YmI0XzEyMDB4NjMwLnBuZw== 1456w" sizes="100vw"/><img src="https://reader.miniflux.app/proxy/4VU0IjuyS-RC71GYF_GS58A7-j2cKOMRSM6pOG4rI-Y=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMDVkYWU3ZmItOTliMi00Y2ZiLWJjMTEtOWY5NzJlMTM0YmI0XzEyMDB4NjMwLnBuZw==" alt="" srcset="https://reader.miniflux.app/proxy/olU7oy8EseZyYZEq15H3xdZ_XIolmT6mk3guVHjuhWI=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYwNWRhZTdmYi05OWIyLTRjZmItYmMxMS05Zjk3MmUxMzRiYjRfMTIwMHg2MzAucG5n 424w, https://reader.miniflux.app/proxy/qbT6mCb49zBq_nxG2-NomPUxrAMSE9tTyt09A-_wKFM=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkYwNWRhZTdmYi05OWIyLTRjZmItYmMxMS05Zjk3MmUxMzRiYjRfMTIwMHg2MzAucG5n 848w, https://reader.miniflux.app/proxy/Rx6umwvX1bAqH_NXVgVUmFtRwa0B2kwCP4hemk7E07w=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMDVkYWU3ZmItOTliMi00Y2ZiLWJjMTEtOWY5NzJlMTM0YmI0XzEyMDB4NjMwLnBuZw== 1272w, https://reader.miniflux.app/proxy/4VU0IjuyS-RC71GYF_GS58A7-j2cKOMRSM6pOG4rI-Y=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGMDVkYWU3ZmItOTliMi00Y2ZiLWJjMTEtOWY5NzJlMTM0YmI0XzEyMDB4NjMwLnBuZw== 1456w" sizes="100vw" loading="lazy"/></picture></a></figure><p><strong>The ultimate catastrophe.</strong> Before Los Alamos, Oppenheimer met with fellow physicist Edward Teller to discuss the end of the world. Teller had begun to worry that a nuclear detonation might fuse atmospheric nitrogen in a catastrophic chain-reaction that would raze the surface of the earth. Disturbed, they reported the possibility to Arthur Compton, an early leader of the Manhattan Project. Compton later <a href="http://large.stanford.edu/courses/2015/ph241/chung1/docs/buck.pdf" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">recalled</a> that it would have been “the ultimate catastrophe.&#34;</p><p>After some initial calculations, another physicist on the project, Hans Bethe, concluded that such a catastrophe was impossible. The project later commissioned <a href="https://sgp.fas.org/othergov/doe/lanl/docs1/00329010.pdf" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">a full report</a> on the possibility, which came to the same conclusion. Still, the fear of catastrophe lingered on the eve of the Trinity test. Just before the test, Enrico Fermi jokingly took bets on the end of the world. </p><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7fb392f-49fe-40a7-a49f-f2dd9c12cd79_1600x944.png" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"><picture><source type="image/webp" srcset="https://reader.miniflux.app/proxy/0tusIdVIdeKU8YYgDBcSEsFcmTkF1KcxRSDvPnezBI8=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiN2ZiMzkyZi00OWZlLTQwYTctYTQ5Zi1mMmRkOWMxMmNkNzlfMTYwMHg5NDQucG5n 424w, https://reader.miniflux.app/proxy/SAmrtguzgFrx6EN4aWAd_d0N2D5rt-8cGwl2uVjdM10=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiN2ZiMzkyZi00OWZlLTQwYTctYTQ5Zi1mMmRkOWMxMmNkNzlfMTYwMHg5NDQucG5n 848w, https://reader.miniflux.app/proxy/hMRK-ggttRXxm4l0GukP8OnJzN08ZbDH3OkVUFqSWio=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYjdmYjM5MmYtNDlmZS00MGE3LWE0OWYtZjJkZDljMTJjZDc5XzE2MDB4OTQ0LnBuZw== 1272w, https://reader.miniflux.app/proxy/YwpVSr2SOk1z3q90NuZSnApkSSVS9aUseHNQUPH2el4=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYjdmYjM5MmYtNDlmZS00MGE3LWE0OWYtZjJkZDljMTJjZDc5XzE2MDB4OTQ0LnBuZw== 1456w" sizes="100vw"/><img src="https://reader.miniflux.app/proxy/WQ4F80_y0ZaniJc1dr5AbJnRwRdWOgPXpZGQ8pRWF1Y=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYjdmYjM5MmYtNDlmZS00MGE3LWE0OWYtZjJkZDljMTJjZDc5XzE2MDB4OTQ0LnBuZw==" alt="" srcset="https://reader.miniflux.app/proxy/mV-r1jvdcrJdHPcpO1_OG9-lheGr9cKa3Fqke_iqDhg=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiN2ZiMzkyZi00OWZlLTQwYTctYTQ5Zi1mMmRkOWMxMmNkNzlfMTYwMHg5NDQucG5n 424w, https://reader.miniflux.app/proxy/ATMBZ4LvDGkfkEcyEaWqsaMCQGdA-RM3HUjMR_AEgxI=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkZiN2ZiMzkyZi00OWZlLTQwYTctYTQ5Zi1mMmRkOWMxMmNkNzlfMTYwMHg5NDQucG5n 848w, https://reader.miniflux.app/proxy/eTh689MMyvnDYYDqdlIQsUWURmENeoRsF4BNiaC2Ymo=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYjdmYjM5MmYtNDlmZS00MGE3LWE0OWYtZjJkZDljMTJjZDc5XzE2MDB4OTQ0LnBuZw== 1272w, https://reader.miniflux.app/proxy/WQ4F80_y0ZaniJc1dr5AbJnRwRdWOgPXpZGQ8pRWF1Y=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGYjdmYjM5MmYtNDlmZS00MGE3LWE0OWYtZjJkZDljMTJjZDc5XzE2MDB4OTQ0LnBuZw== 1456w" sizes="100vw" loading="lazy"/></picture></a><figcaption><em>Photo of the Trinity test, which some feared could cause a global catastrophe. </em></figcaption></figure><p><strong>Objective and subjective probability.</strong> In Nolan’s film, Oppenheimer tells the military director of the Manhattan Project, Leslie Groves, that the probability of a catastrophe during the Trinity test was “near zero.” The film might be drawing from <a href="http://large.stanford.edu/courses/2015/ph241/chung1/docs/buck.pdf" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">an interview</a> with Compton, who recalled that the probability was three parts in a million. Bethe was less equivocal. He <a href="https://www.tandfonline.com/doi/abs/10.1080/00963402.1976.11455623" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">writes</a> that “there was never a possibility of causing a thermonuclear chain reaction in the atmosphere,” and that “[i]gnition is not a matter of probabilities; it is simply impossible.”</p><p>Bethe is right in one sense: the report did not give any probabilities. It concluded that catastrophe was objectively impossible. Where Bethe errs is in conflating <em>objective</em> and <em>subjective</em> probability. The calculations in the report implied certainty — but Bethe should have been uncertain about the calculations themselves, and the assumptions those calculations relied on.</p><p>The mathematician R.W. Hamming <a href="https://www.tandfonline.com/doi/abs/10.1080/00029890.1998.12004938" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">recalls</a> that at least one of the report’s authors was uncertain leading up to the Trinity test:</p><blockquote><p>Shortly before the first field test (you realize that no small scale experiment can be done — either you have a critical mass or you do not), a man asked me to check some arithmetic he had done, and I agreed, thinking to fob it off on some subordinate. When I asked what it was, he said, &#34;It is the probability that the test bomb will ignite the whole atmosphere.&#34; I decided I would check it myself! The next day when he came for the answers I remarked to him, &#34;The arithmetic was apparently correct but I do not know about the formulas for the capture cross sections for oxygen and nitrogen — after all, there could be no experiments at the needed energy levels.&#34; He replied, like a physicist talking to a mathematician, that he wanted me to check the arithmetic not the physics, and left. I said to myself, &#34;What have you done, Hamming, you are involved in risking all of life that is known in the Universe, and you do not know much of an essential part?&#34;</p></blockquote><p>Doubt lingered in the final moments preceding the Trinity test about the possibility of a catastrophic chain reaction. Hans Bethe’s calculations may have shown that the probability of catastrophe was zero, but it remained possible that Bethe had miscalculated. </p><p>Scientific and mathematical claims that are widely accepted can still be false. For example, a peer-reviewed mathematical proof of the famous four color problem was accepted for years until, finally, <a href="https://en.wikipedia.org/wiki/Four_color_theorem" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">a flaw was uncovered</a>. While Bethe’s model was confident, he shouldn’t have placed his full faith in a model without the test of time. </p><p><strong>The Castle Bravo Disaster. </strong>Indeed, the probability of a theoretical mistake may have been quite high. Trinity didn’t end in catastrophe, but another initial test — Castle Bravo — did. Castle Bravo was the first test of a dry-fuel hydrogen bomb. Because of an unexpected nuclear interaction, the payload of the bomb was three times greater than predicted. Its fallout reached the inhabitants of the Marshall Islands, as well as a nearby Japanese fishing vessel, leading to dozens of cases of acute radiation sickness. </p><p>There is no reason to think that the authors of the atmospheric ignition report couldn’t have made a similar mistake. Indeed, one of the authors, Edward Teller, designed the bomb used in the Castle Bravo test. Trinity didn’t end in catastrophe, but it could have. </p><p><strong>Lessons for AI safety.</strong> Despite a firm grasp of the nuclear reaction principles at the time of the Trinity test, there were still a handful of experts voicing concerns about the potentially disastrous outcomes. Those who conducted the test accepted a risk that, if their calculations were wrong, the atmosphere would be ignited and all of humanity thrown into catastrophe. While the test was ultimately successful, it would have been prudent to consider these concerns more seriously before the Trinity test at Los Alamos. </p><p>Artificial intelligence, on the other hand, is understood far less than nuclear reactions were. Moreover, a substantial number of experts have <a href="https://www.safe.ai/statement-on-ai-risk" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">publicly warned</a> about the existential risk emanating from AI. It’s crucial to ensure there’s consensus that risks are negligible or zero and that this consensus<s> </s> passes the test of time before taking actions that could cause extinction. </p><p><a href="https://newsletter.safe.ai/subscribe?" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Subscribe now</a></p><h2>Links</h2><ul><li><p>To help AI companies assess the risks of their models, a <a href="https://arxiv.org/abs/2307.08823" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">new paper reviews common risk assessment techniques</a> in other fields. </p></li><li><p>A detailed explanation of how <a href="https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Chinese AI policy</a> gets made.</p></li><li><p>To verify the data that an AI was trained on, a <a href="https://arxiv.org/abs/2307.00682" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">new paper</a> proposes a solution involving saving checkpoints of a model throughout its training process. </p></li><li><p><a href="https://thehackernews.com/2023/07/wormgpt-new-ai-tool-allows.html" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">WormGPT</a> is a new AI tool for launching offensive cyber attacks.</p></li><li><p>Prominent technologists are pushing for no regulation of AI under the banner of a <a href="https://twitter.com/DanHendrycks/status/1651740865159901184" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Darwinian ideology</a>.</p></li><li><p>A <a href="https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-principles-for-regulation" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">senate subcommittee</a> is having a hearing on AI regulation. All three speakers (Russell, Amodei, Bengio) have signed the <a href="https://safe.ai/statement-on-ai-risk" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">statement on AI risk</a>.</p></li><li><p>The UN Security Council had its <a href="https://media.un.org/en/asset/k1j/k1ji81po8p" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">first meeting on AI risk</a>. A number of representatives, including the UN Secretary General, explicitly mentioned AI x-risk.</p></li></ul><p>See also: <a href="https://www.safe.ai/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">CAIS website</a>, <a href="https://twitter.com/ai_risks?lang=en" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">CAIS twitter</a>, <a href="https://newsletter.mlsafety.org/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">A technical safety research newsletter</a>, and <a href="https://arxiv.org/abs/2306.12001" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">An Overview of Catastrophic AI Risks</a></p><p><a href="https://newsletter.safe.ai/p/ai-safety-newsletter-16?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Share</a></p>