<p>It’s been a very hard week for UNC students, faculty, and staff. We want to thank everyone who reached out to us to check in, and make sure we were okay. Before we discuss publications, appearances, and more this week at CITAP, we want to take a moment to pause and remember Dr. Zijie Yan.</p><p>Dr. Yan joined UNC in the Applied Physical Sciences department in 2019 as an Associate Professor. He was an accomplished researcher, completing his PhD program at Rensselaer Polytechnic Institute. He served as a postdoc at the University of Chicago, assistant professor at Clarkson University, then came to UNC.</p><p>Dr. Yan was a husband, father, friend, brilliant researcher. The UNC community mourns his loss, and we think of his friends and family as they grieve.</p><h2>Affordance Activation &amp; Disinfo Spread</h2><p>Affordances are “the perception of what a technical artifact can do”; when it comes to interactive technological systems, however, “affordances can be more than just perceptible features; sometimes they can be hidden, only revealed through active exploration.” In “<strong><a href="https://doi.org/10.1080/1369118X.2023.2245869" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">‘Do your own research’: affordance activation and disinformation spread</a></strong>”, Francesca Tripodi, Lauren Garcia, and Alice Marwick assert that the user interacting with the technological affordance, which then gives agency to the platform or technology, “further authorizes, allows, and amplifies the spread of inaccuracies online.” This framing draws in the interactive dimensions of affordance theory, referring to Marwick’s <strong><a href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=2&amp;publication_year=2018&amp;pages=474-512&amp;journal=Georgetown+Law+Technology+Review&amp;issue=2&amp;author=A.+E.+Marwick&amp;title=Why+do+people+share+fake+news%3F+A+sociotechnical+model+of+media+effects" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">sociotechnological model on media effects</a></strong>. The authors argue that combatting misinformation is not about intent or accuracy, as the cases they analyze deal with audience interaction with technological affordances, not the claim that those spreading information are making.</p><p>One of these case studies in the paper includes the de-platforming of then-President Trump on January 8, 2021. The co-founder of <em>The Federalist</em> bemoaned this decision, tweeting that the decision to ban Trump from Twitter was “akin to censoring conservatism.” He tried to hashtag 1984 (stylized #1984), but discovered that he could not. He alleged that Twitter was making discussion of this de-platforming harder to occur by not allowing #1984 to be written, implying it was an attempt to silence conservatism.</p><p>Twitter does not allow for any series of numbers to be hash tagged on their own, but the claim that #1984 was not allowed activated a number of conservative followers to engage with this (i.e. hashtag affordance), and tweet, retweet, or quote the original tweet, as they were also unable to activate the hashtag affordance. “By interacting with the platform, but not understanding the limitation of the hashtag affordance, people were able to ‘prove’ the argument and validate the frame that Big Tech silences conservatism.”</p><p>Ultimately, the authors state that “by activating technological affordances such as hashtags, citation systems, and search engine optimization, the manipulation process encourages audiences to engage with false claims in ways that further confirm their beliefs.” As audiences engage with false claims and activate technological affordances, this process also draws on the “do-it-yourself process of information seeking, this ‘IKEA Effect of misinformation” that empowers audiences with a false autonomy, leading them to believe they are “doing their own research” and finding their own conclusions. In this way, the spread of disinformation continues to become a more participatory and engaging process.</p><h2>Publications and appearances</h2><p>“[There’s a common belief that] privacy violations happen when individuals reveal their own information… Generative AI completely obliterates the idea of individual responsibility for privacy because you can’t control these algorithms’ access to your information, or what they do with it. Generative AI shows the threadbare seams of our out-of-date, individual-responsibility model of privacy; it’s time we recognized its futility and moved beyond it.” Alice Marwick wrote in Wired about <strong><a href="https://wired.me/culture/online-privacy/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">privacy and (the futility of) individual responsibility in the age of generative AI</a></strong>.</p><p>“Marwick said that within the internet landscape of the 2000s, Google was the thing that sat on top of everything else. There was a sense that as anarchic and chaotic as the early social web was out in the digital wilderness, what Google surfaced denoted a certain level of quality.” Alice spoke with The Verge regarding the <strong><a href="https://www.theverge.com/23846048/google-search-memes-images-pagerank-altavista-seo-keywords" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">history of Google and its current status</a></strong>.</p><p>“Black people—and Black women especially—are shut out of traditional employment, but our culture applauds the hustler who responds to exclusion by striking out on her own. Black women platform entrepreneurs have more education than their white male and female counterparts. Despite having more formal education, they face more job insecurity than similarly educated peers.” Tressie McMillan Cottom is quoted in a Yes Magazine piece on <strong><a href="https://www.yesmagazine.org/issue/growth/2023/08/31/reject-career-growth-mindset" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">“growth mindset” and hustle culture</a></strong>.</p><p>In speaking to the Chronicle of Higher Education about the <strong><a href="https://www.chronicle.com/article/is-academictwitter-over" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">decline of academic Twitter</a></strong>, Tressie McMillan Cottom stated “there’s no way that the scale of my career, and the trajectory of it, would have happened without Twitter,” but it has been “absolutely brutal and horrible” to her as an individual.</p><h2>Coming Soon</h2><p><strong>September 7 at 3pm</strong>: CITAP is hosting Lee McGuigan for a book talk on his book “<strong><a href="https://mitpress.mit.edu/9780262545440/selling-the-american-people/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Selling the American People: Advertising, Optimization, and the Origins of Adtech</a></strong>.” In the Freedom Forum and via livestream: <strong><a href="https://citap.unc.edu/events/lee-mcguigan-selling-the-american-people/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">details and RSVP</a></strong>.</p><p><strong>October 16 at CITAP</strong>: Misinformation and Marginalization Symposium. How does misinformation circulate in marginalized communities, and what misinformation narratives are shared about marginalized groups?</p><p>Featuring a keynote from Dr. Sarah Banet-Weiser and panels on misinformation and gender &amp; sexuality; diasporic communities; and algorithmic amplification, race, and religion. <strong><a href="https://www.eventbrite.com/e/misinformation-and-marginalization-tickets-700299052317?aff=oddtdtcreator" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Free registration required to join in person or virtually</a></strong>!</p><p><strong>October 18 at AoIR</strong>: Alice Marwick, Yvonne Eadon, and Rachel Kuo are among the co-organizers of an <strong><a href="https://aoir.org/aoir2023/preconfworkshops/#future" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">AoIR preconference on future of conspiracy</a></strong>.</p><p><strong>October 20 at AoIR</strong>: CITAP, <strong><a href="https://www.asc.upenn.edu/research/centers/center-on-digital-culture-and-society" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">CDCS</a></strong>, and <strong><a href="https://iddp.gwu.edu/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">IDDP</a></strong> are co-hosting a networking Happy Hour on Sunday, October 20th at 6pm. More details to follow!</p><p><strong>October 22 at the Annenberg Public Policy Center</strong>: The Post-API Conference.</p><p><strong>November 10 at CITAP</strong>: Symposium on Religion, Media, and Public Life.</p><p>Confirmed panelists include Whitney Phillips, Samuel Perry, Eden Consenstein, Xavier Pickett, Erika Gault, and Heidi Campbell, with additional participants to be named in the weeks to come. <strong><a href="https://www.eventbrite.com/e/religion-media-public-life-tickets-700337517367?aff=oddtdtcreator" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Register to join in person or virtually</a></strong>!</p>