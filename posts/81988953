<p>Hi everyone,</p>
<h2>New posts</h2>
<ol>
<li><a href="https://guzey.com/advice-from-tyler-cowen?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Advice from Tyler Cowen.</a><ul>
<li>Top rated MR <a href="https://marginalrevolution.com/marginalrevolution/2023/07/alexey-summarizes-the-advice-he-hears-me-give-people.html?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">comment</a> is ofc &#34;<em>This is just so very blindingly false</em>&#34; ğŸ™‚</li>
</ul>
</li>
<li><a href="https://guzey.com/questions/?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Questions</a>.<ol>
<li>Tim Ferriss: <a href="https://newsletterhunt.com/emails/35766?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">&#34;The English is a little rough in places, but I found some of these questions to be excellent reminders and many others to be outstanding brain food.&#34;</a> ğŸ¥² </li>
</ol>
</li>
<li><a href="https://guzey.com/pulp-fiction/?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">10 notes from watching pulp fiction yet again</a></li>
</ol>
<h2>Links</h2>
<ol>
<li>Anthropic: <a href="https://twitter.com/AnthropicAI/status/1681341068774875139?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Reasoning faithfulness shows inverse scaling: as models increase in size and capability, the faithfulness of their reasoning decreases for most tasks studied.</a></li>
<li>Andy Zou: <a href="https://twitter.com/andyzou_jiaming/status/1684766170766004224?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">&#34;We found adversarial suffixes that completely circumvent the alignment of open source LLMs. More concerningly, the same prompts transfer to ChatGPT, Claude, Bard, and LLaMA-2â€¦&#34;</a></li>
<li>Cade Metz: <a href="https://www.nytimes.com/2023/03/31/technology/sam-altman-open-ai-chatgpt.html?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">â€œMr. Altman pointed out that, as fate would have it, he and Oppenheimer share a birthday.â€</a></li>
</ol>
<h2>Other</h2>
<ol>
<li>My blog now has academic citations in 4 separate scientific fields: economics, metascience, neuroscience, &amp; <a href="https://arxiv.org/pdf/2307.02483.pdf?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">AI</a> ğŸ«¡</li>
<li>whatâ€™s the global compute distribution between companies and governments?</li>
<li>Tony Kulesa: <a href="https://www.tonykulesa.com/p/a-relatively-small-amount-of-force?utm_source=guzey&amp;utm_medium=email&amp;utm_campaign=july-2023-updates" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">&#39;[PG] abruptly clarified: &#34;Oh, not me!&#34; The rumble of one hundred simultaneously disappointed nerds echoed through the roomâ€¦.&#39; a few weeks later, in March 2005, Paul announced YC on his website.</a></li>
</ol>

<p>Have a great rest of your month &amp; as always feel free to reach out!</p>
<p>Stay frosty,<br/>
Alexey</p>

