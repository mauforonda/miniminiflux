<p></p><figure><a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f1de3a7-d338-433f-90a5-2b8f0b80da5f_1042x543.png" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"><picture><source type="image/webp" srcset="https://reader.miniflux.app/proxy/fR0U2ftqTbkWT5reHJPer_Xnlwc2vzK_2itYI2Qf9do=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkY5ZjFkZTNhNy1kMzM4LTQzM2YtOTBhNS0yYjhmMGI4MGRhNWZfMTA0Mng1NDMucG5n 424w, https://reader.miniflux.app/proxy/9mrsK9zvyIlTOChbDZVa0RQeKLFUujxh5bus8dA7l_E=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX3dlYnAscV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkY5ZjFkZTNhNy1kMzM4LTQzM2YtOTBhNS0yYjhmMGI4MGRhNWZfMTA0Mng1NDMucG5n 848w, https://reader.miniflux.app/proxy/_lhDy4mwmHWCNQSzWgcMQ43dAZZT0wzKlXiZTTHQum8=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGOWYxZGUzYTctZDMzOC00MzNmLTkwYTUtMmI4ZjBiODBkYTVmXzEwNDJ4NTQzLnBuZw== 1272w, https://reader.miniflux.app/proxy/K4qoBQGXDgr-nQfpR4k3QB-pMaY0Et4Q04VLoFC30po=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl93ZWJwLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGOWYxZGUzYTctZDMzOC00MzNmLTkwYTUtMmI4ZjBiODBkYTVmXzEwNDJ4NTQzLnBuZw== 1456w" sizes="100vw"/><img src="https://reader.miniflux.app/proxy/gf-ZYcptB1OATid_dYytkvf0iN7Qn_1HAb-A5-9zLf8=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGOWYxZGUzYTctZDMzOC00MzNmLTkwYTUtMmI4ZjBiODBkYTVmXzEwNDJ4NTQzLnBuZw==" alt="" srcset="https://reader.miniflux.app/proxy/sMacVamZ7-g6Msmlbn-MEnLmKRmCmYXeWm5TywVrOXQ=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd180MjQsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkY5ZjFkZTNhNy1kMzM4LTQzM2YtOTBhNS0yYjhmMGI4MGRhNWZfMTA0Mng1NDMucG5n 424w, https://reader.miniflux.app/proxy/sjqbBvVjaW241P6cCZsGO4wBFZuVQK-g8hejwF92O3o=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd184NDgsY19saW1pdCxmX2F1dG8scV9hdXRvOmdvb2QsZmxfcHJvZ3Jlc3NpdmU6c3RlZXAvaHR0cHMlM0ElMkYlMkZzdWJzdGFjay1wb3N0LW1lZGlhLnMzLmFtYXpvbmF3cy5jb20lMkZwdWJsaWMlMkZpbWFnZXMlMkY5ZjFkZTNhNy1kMzM4LTQzM2YtOTBhNS0yYjhmMGI4MGRhNWZfMTA0Mng1NDMucG5n 848w, https://reader.miniflux.app/proxy/1z4B9BFJxCCXTjvnHvUPV2DrazG-iF0JTT07G-LA6Ag=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xMjcyLGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGOWYxZGUzYTctZDMzOC00MzNmLTkwYTUtMmI4ZjBiODBkYTVmXzEwNDJ4NTQzLnBuZw== 1272w, https://reader.miniflux.app/proxy/gf-ZYcptB1OATid_dYytkvf0iN7Qn_1HAb-A5-9zLf8=/aHR0cHM6Ly9zdWJzdGFja2Nkbi5jb20vaW1hZ2UvZmV0Y2gvd18xNDU2LGNfbGltaXQsZl9hdXRvLHFfYXV0bzpnb29kLGZsX3Byb2dyZXNzaXZlOnN0ZWVwL2h0dHBzJTNBJTJGJTJGc3Vic3RhY2stcG9zdC1tZWRpYS5zMy5hbWF6b25hd3MuY29tJTJGcHVibGljJTJGaW1hZ2VzJTJGOWYxZGUzYTctZDMzOC00MzNmLTkwYTUtMmI4ZjBiODBkYTVmXzEwNDJ4NTQzLnBuZw== 1456w" sizes="100vw" loading="lazy"/></picture></a><figcaption>Jeff Goldblum’s immortal line in the movie of Michael Crichton’s Jurassic Park</figcaption></figure><p></p><p>If I could make one change to <a href="http://rebooting.ai" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Rebooting AI</a>, the 2019 book I co-wrote with Ernie Davis, it might well be to boldface this passage:</p><p><strong>AI, like any technology, is subject to the risk of unintended consequences, quite possibly more so, and the wider we open Pandora’s box, the more risk we assume. We see few risks in the current regime, but fewer reasons to tempt fate by blithely assuming that anything that we might invent can be dealt with.</strong></p><p>My reason for mentioning this now is that an all-star cast of philosophers and AI researchers has <a href="https://arxiv.org/abs/2308.08708" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">just posted a paper on arXiv</a> that not only considered the criteria for building conscious machines, but also provides “<a href="https://x.com/ericelmoznino/status/1693477301554762077?s=61&amp;t=2voLMkhJf6P349CqztWSAQ" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">some tentative sketches</a>” for how to build one.</p><p>Honestly, is that a good idea? </p><p> We can’t even control LLMs. Do we really want to open another, perhaps even riskier box?  </p><p>We all know what Michael Crichton would be writing about today.</p><p>Thank you for reading Marcus on AI. This post is public so feel free to share it.</p><p><a href="https://garymarcus.substack.com/p/sentient-ai-for-the-love-of-darwin?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Share</a></p><p><strong>Gary Marcus</strong> doesn’t, contrary a common belief, hate AI; he just wants a world in which AI is net positive. Is that too much to ask?</p><p><a href="https://garymarcus.substack.com/subscribe?" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Subscribe now</a></p>