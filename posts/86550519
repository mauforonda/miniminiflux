<p>Welcome to the first edition of “CITAP Sounds Off”, the occasional newsletter where you can expect op-eds, essays, rants &amp; more.</p><p><strong>Katie Harbath and Daniel teamed up this week to take a deep dive into the history of tech and elections.</strong> </p><p>Check out Katie’s platform trust and safety work over at <strong><a href="https://www.anchorchange.com/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">Anchor Change</a></strong> and sign up for <strong><a href="https://anchorchange.substack.com/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">her essential substack</a></strong> on tech and democracy. </p><p>The U.S. will elect a president in 2024 but it is only one among many countries with upcoming elections. India, Mexico, Taiwan, Ukraine, and the U.K. and European Parliament will also elect new leaders. Overall, more than fifty democracies worldwide will hold elections in 2024. </p><p>This comes at a time when democracy is under threat around the world. In countries from the United States, Israel, and India to Brazil, Hungary, and Nigeria, leaders have undermined democratic norms, the rule of law, or the peaceful transfer of power. Many factors contribute to this, but in recent years technology and social media platforms have received much attention for their roles in straining democracy and their responsibility to protect the public and democratic institutions.</p><p>We are at a very different moment from twenty years ago when we started our respective work. Katie’s first job in 2003 was running the e-campaign at the Republican National Committee. She then worked as a digital staffer for Republican campaigns through 2010 and joined Facebook in 2011. There, she built the teams that work with politicians and governments to use the platform and coordinated the company’s work on elections worldwide from 2013 to the end of 2019. Daniel, for his part, wrote about the internet-fueled Howard Dean campaign in Iowa during the caucuses in 2004 and then the Obama 2008 and 2012 campaigns as part of the first group of researchers seeking to understand social media and politics. In 2019, Daniel co-founded the UNC Center for Information, Technology, and Public Life to research mis- and disinformation, platforms, and threats to democracy.</p><p>It might be hard to remember, but generally, until 2016, platforms and social media were <strong><a href="https://bipartisanpolicy.org/report/history-tech-elections/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">heralded for the ways they furthered democracy</a></strong>. Many celebrated how candidates could get their messages directly in front of voters, routing around the filter of sensationalistic media and soundbite-oriented professional journalists. Everyday people could use social media to organize, make phone calls, debate policy, and even speak to political leaders. Campaigns used new digital tools to engage voters in ways that looked very different from the era of broadcast advertising, with its passive, one-way messaging.</p><p>All of these things look very different now. The same things that were equated with democracy in 2008 and 2012 look darker amid fears of disinformation, harassment, hate speech, voter suppression, and even deadly violence directed at state officials in many countries around the world.</p><p>In response to these opportunities and threats, social media platforms have adapted, developing and evolving their roles and policies. They do so while also operating as the primary means through which hundreds of millions of people worldwide participate in politics, learn about elected officials and political issues, and engage in democratic processes. </p><p>In this essay, we reflect back on twenty years of social media and political life amid a time of deep uneasiness for democracies around the world. We do so through the lens of the various policies the global companies that provide technology and social media platforms adopt in the context of elections – as well as what we argue these companies and other stakeholders <em>should </em>do. </p><p>What happens in the next two years will shape the next twenty.</p><h3><strong>The History of Social Media and Politics </strong></h3><p>Before 2016, few platforms had specific, electoral-related policies. All major platforms operating out of the U.S. had content rules that evolved over time as various controversies forced them to adapt and adjust. Many of these were political. Examples include whether or not to allow pictures of women breastfeeding where you can see the nipple. Or to allow the famous “Napalm Girl &#39;&#39; photograph depicting a naked child in the course of documenting the horrors of U.S. bombing during the Vietnam War. These decisions were often made by balancing competing values over expression, protecting harms, and commercial interests. </p><p>There seemed to be little need for election-related policies. Indeed, in the pre-2016 era platforms were generally seen as not only complementary to democracy but even helping to bring it about in autocratic countries. The 2008 and 2012 Obama campaigns in the U.S. cemented a general belief in the democratizing nature of the Internet. The <strong><a href="https://content.time.com/time/specials/packages/article/0,28804,2036683_2037183_2037185,00.html" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">animating spirit</a></strong> of the age seemed to be democratic participation, where everyday folks had more opportunities for political power. Perhaps no greater example was on display than the “Arab Spring” – that romanticized wave of democratic protests that swept the Middle East during 2011 and 2012 – giving rise to the idea that digital media were forms of <strong><a href="https://www.journalofdemocracy.org/articles/liberation-technology/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">“liberation technology.”</a></strong><a href="https://www.journalofdemocracy.org/articles/liberation-technology/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"> </a></p><p>It is hard to remember such a moment of optimism after the darker times that followed. The Arab Spring ended in the “Arab Winter” of resurgent autocracy and ethno-religious, one-party states or hybrid regimes. 2016 was a monumental year, starting with the Philippines election, which saw Rodrigo Duterte come to power, and then the withdrawal of the U.K. from the European Union (Brexit) and the election of U.S. president Donald Trump. Social media companies were blamed (we believe unfairly) by commentators for many of these things amid high-profile attention over Cambridge Analytica, Russian disinformation, and mis- and disinformation. </p><p>We say unfairly not because these things weren’t concerning – they were – but because the outcry was more directed at a convenient target than a clear political analysis. Many journalists, researchers, academics, and policymakers were blind to underlying contests over status and political power among contending social groups – and especially political challenges to historically dominant racial and ethnic groups in many western democracies. Indeed, platforms <strong><a href="https://www.nytimes.com/interactive/2019/12/27/opinion/sunday/twitter-social-media.html" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">fueled the unprecedented pro-democratic racial justice organizing</a></strong> in the U.S., the backlash to which has defined our elections since. </p><p>Indeed, there is <strong><a href="https://www.nytimes.com/2023/07/27/technology/facebook-instagram-algorithms.html" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">scant evidence</a></strong> that platforms have brought about the polarization, extremism, sectarianism, partisanship, and ideological close-mindedness that <strong><a href="https://www.theatlantic.com/magazine/archive/2022/05/social-media-democracy-trust-babel/629369/" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">many decry</a></strong> at the root of our contemporary political ills – although they likely play a role in reinforcing and amplifying these things.</p><p>A monumental <strong><a href="https://www.nyu.edu/about/news-publications/news/2023/july/2020-election-studies-reveals-power-of-facebook--instagram-algor.html" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">series of studies</a></strong><a href="https://www.nyu.edu/about/news-publications/news/2023/july/2020-election-studies-reveals-power-of-facebook--instagram-algor.html" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"> </a>on platforms published recently has shown that, generally, people’s political beliefs, social identities, and interests come first – with exposure to information on platforms such as Facebook generally having limited impact on polarization and extremist political attitudes. While not perfect, these studies represent the best evidence to date on platforms’ roles in politics. These findings also confirm other important things. Platforms do not exist in vacuums – politicians’ speeches, emails, party communications, television, radio, websites, entertainment media, churches and mosques, and many other things all shape how people think and feel about politics and perceive their interests. It was always a myth – and an apolitical one at that – to believe that platforms were the primary cause of our political ills.</p><p>That said, the question of what platforms <em>should </em>be responsible for persists, especially as it is clear that political elites have used platforms to undermine their own accountability at the ballot box, even as their supporters organize on them to subvert the peaceful transfer of power. Responding to this has only grown more more urgent after the 2020 U.S. presidential election, the rise of ethno–nationalistic leaders such as Modi in India, the attempted coup in the U.S. on January 6, 2021, and the January 8, 2023 attacks by supporters of Bolsonaro on governmental buildings in Brazil. </p><p>Platforms certainly have acknowledged their own responsibility for democracy in recent years. After 2016, many platforms facing intense public pressure voluntarily developed stronger content rules against voter suppression and political violence. They created civic integrity teams to combat harm. They embraced their role of promoting political participation by creating voter information centers and helping people register to vote. A number implemented new requirements for political advertisers - including identity verification, disclaimers, and ad libraries where anyone could see the ads being run. Others, including Twitter, banned ads before the 2020 election, and Facebook imposed a blackout period the week before the vote – with the stated intention to protect the integrity of voting. And, in the wake of the attempted coup on January 6th, most major US-based platforms deplatformed then-President Trump.</p><p>Increasingly, however, we see the rolling back of many measures put in place to combat things such as mis- and disinformation. This has come after significant pushback, particularly on the right who are riding claims of censorship, as well as enduring orientations toward ‘free expression’ as a political value that platforms must protect and which is enshrined in the universal declaration of human rights adopted by the UN general assembly. This human rights orientation provides much of the backdrop to the decision making of platforms, including those bodies such as the Facebook Oversight Board, which rules on the company’s moderation decisions based on  Facebook’s own policies, value of free expression, and evaluation of potential harms. </p><p>Many platforms are now trying to avoid politics. Some, such as Meta which consists of the platforms Facebook, Instagram, WhatsApp and Threads, have openly said they are deprioritizing news and political content. While X (formerly Twitter) has re-embraced political ads, TikTok has banned political advertising and doesn’t allow campaigns to fundraise on their platform. YouTube and Meta recently decided to rollback some election protections that emerged in the wake of the 2020 U.S. presidential election (such as denying the results of that election.) </p><p>Indeed, the 2020 cycle was likely the peak of political content moderation by global platforms. The move to engage in less political content moderation has momentum for several reasons. First, the stated value of free expression alongside the belief that democratic publics should be able to hear from those seeking to represent them. Second, for many global companies, not actively moderating content offers organizational and political advantages. It’s hard, requiring employee resources and systems to facilitate it. A hands-off approach helps companies avoid accusations of bias and political liabilities as parties change power – including regulations (even as some stakeholders are pushing for greater regulation, especially in the European Union). </p><p>Without mechanisms to compel platforms to continue the hard work of protecting elections, we will remain at their whims. However, relying on regulatory compulsion alone is also complicated. Different countries and regions are taking different approaches - and in some, <strong><a href="https://www.theguardian.com/world/2023/apr/05/twitter-accused-of-censorship-in-india-as-it-blocks-modi-critics-elon-musk" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">parties in power  are weaponizing laws to silence their political opponents</a></strong>. The United States has been hands-off while the European Union has focused more on requiring transparency. Even when governments are legally hands-off, however,<a href="https://knightcolumbia.org/blog/jawboned?utm_source=substack&amp;utm_medium=email" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer"> </a><strong><a href="https://knightcolumbia.org/blog/jawboned?utm_source=substack&amp;utm_medium=email" rel="noopener noreferrer" target="_blank" referrerpolicy="no-referrer">platforms can find themselves pressured by officials to implement policies</a></strong> they cannot otherwise pass. </p><p>Looking beyond 2024, the geopolitics of tech will become even more important. </p><h3><strong>Looking Forward</strong></h3><p>We face an uncertain year. Technological advances, particularly in artificial intelligence, have created new opportunities and threats for democratic processes. There are new platforms – not only TikTok but also Discord, Telegram, and Twitch that have become new means of political communication. If there is anything we have learned, such as from X (Twitter), platforms do not need big numbers to have a big impact. </p><p>Consider one example of how every election differs as media and technologies evolve: artificial intelligence. The dangers of AI are endlessly debated in public discourse. To date, they have centered around the trustworthiness of claims in political debate. In a moment when content can make its way around the world in the blink of an eye, there is a real danger for bad actors to use AI to manipulate voters. We also see many more mundane ways that AI will challenge the informational environments of platforms in the context of elections. AI-generated spam, for instance, has the capacity to drown out actual citizen’s voices in public debate, as is happening in reviews for commercial products on platforms such as Amazon. </p><p>On the other hand, AI can be used to detect this content and remove it faster. Moreover, as decades of political science tell us, people are rarely the dupes of mis- or disinformation, including sophisticated AI-created content. People are quite discerning of what it is they already believe and accept things that generally are in line with their preexisting attitudes, identities, and interests. </p><p>What is needed for the next generation of trust and safety is a broad framework of checks and balances where governments, platforms, civil society, media, and others all take action to find the best path forward to keeping the Internet a place people still want to be.</p><p>For instance, over the past few months, there’s been a lot of conversation around the use of artificial intelligence in political ads. We’ve seen platforms such as Google proactively change their policies to require that AI used in political ads be labeled. At the same time, agencies such as the Federal Election Commission are soliciting public comments for potential rulemaking on the topic. The European Union has already regulated online political ads through the Digital Services Act. Civil society, academia, and media are monitoring these efforts closely to understand where platforms might be falling short in their enforcement – while also advising governmental bodies and platforms on what should be done and what the threats are. </p><p>This is but one example of how we think <em>all</em> these entities should provide a check on one another. Platforms can always move the fastest, but we also need government action to ensure consistency across companies and to ensure they don’t stop doing the work. And, we need civil society, researchers, and media to monitor platforms – <em>and </em>political leaders – and hold them accountable. </p><p>We also sometimes need platforms to check the power of those who would unfairly and undemocratically seize power. Indeed, from a regulatory perspective, it is clear that governments worldwide – or people and parties in power at various levels of government – have worked to weaponize platform regulation. Examples include India and Brazil and the recent inquiries into disinformation researchers in the United States by Republicans in Congress. In this context, platforms are often incentivized to do less moderation, including of speech that undermines public health and shuts down the political speech of marginalized groups.</p><p>From a platform perspective, a key question is how platforms will respond to content that potentially undermines democratic processes and increased pressure by partisan political  actors. The first wave of platform content policies and enforcement centered on a case-based, evolving set of decisions largely ill-suited to respond to strategic threats, especially by political elites. The next generation of trust and safety responses seems to be taking shape in the context of companies avoiding political pressure. We believe this is misguided: platforms can run from politics, but they cannot hide. </p><p>Political speech will find its way onto even the smallest or unlikeliest platforms - thus, they must engage and be prepared. Thankfully, there are people at these platforms doing the hard work every day trying to protect the integrity of elections online and the safety of people overall. Some who once worked inside the companies are now working for governments and civil society to help pull back the curtain a little bit more to reveal how these platforms operate. And, numerous people in government are trying to write, enact, and enforce regulations to ensure platforms help create healthy societies. </p><p>2024 is taking shape in extraordinary circumstances in the U.S., with former president Trump facing multiple indictments. Numerous other court cases in the States on content moderation and government use of and engagement with online platforms will be decided in the middle of the election year. Platforms in the U.S. are trying to defer more and more to the judicial and institutional context rather than making their own value-based decisions to content moderation. This comes even as it is clear that platforms are weaponized by political leaders seeking to undermine competitive elections – and rolling back policies designed to protect against election disinformation leaves democracy vulnerable.</p><p>No matter what, there will not be a simple solution to these challenges. We believe that these are not easy problems to solve, so having more of these debates out in the open is good. Any trust and safety framework will have a few important elements. Platforms, governments, parties, civil society, academia, media, and others must work to scrutinize and hold one another accountable for actions that threaten elections and the peaceful transfer of power. We need more transparency to what is happening on platforms and their decision-making, including how they are making tradeoffs between incredibly important, competing values. And, platforms should provide people with recourse if they disagree with decisions, and adopt a fundamental understanding that democratic threats manifest differently worldwide. </p><p>There is no one-size-fits-all answer to the difficult challenges we face in democracies around the world.</p><p>None of us can hide from politics - nor should we. A productive democracy requires participation. It requires hard conversations and tough choices to ensure everyone can participate. 2024 will be a huge challenge to platforms – and us all – to ensure democracy survives.</p>